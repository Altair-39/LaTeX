\chapter{Incertezza}

\section{Introduzione}

\qs{}{
  Indichiamo con $A_t$ il piano che ci fa partire per l'aeroporto $t$ minuti prima del decollo. Come stabilire se $A_t$ ci porterà in aeroporto per tempo?}

\paragraph{Problemi:}

\begin{itemize}
  \item Osservabilità parziale (stato delle strade, traffico, etc.). 
  \item Osservazioni imprecise (notizie traffico/meteo inesatte). 
  \item Incertezza sul risultato delle azioni (la macchina non parte). 
  \item Difficile modellare un sistema nel suo complesso.
\end{itemize}

\paragraph{Se si sceglie un approccio puramente logico:}

\begin{itemize}
  \item Si rischia di prendere decisioni errate. 
  \item Si hanno conclusioni \fancyglitter{troppo deboli} per il decision making.
\end{itemize}

\paragraph{Limiti della logica del primordine:}

\begin{itemize}
  \item \fancyglitter{Pigrizia:} elencare un insieme completo di premesse/conseguenze richiede troppo lavoro, le regole diventano difficili da comprendere e utilizzare.
  \item \fancyglitter{Ignoranza teorica:} non conosciamo tutto. 
  \item \fancyglitter{Ignoranza pratica:} anche se conosciamo tutto in generale potremmo avere lacune sul caso specifico.
\end{itemize}

\subsection{Probabilità}

\dfn{Probabilità}{
La probabilità fornisce uno strumento per riassumere l’incertezza che deriva da pigrizia e ignoranza. Si assegna una probabilità a una formula corrisponde al grado di credenza nella verità della formula.
}

\clm{}{}{
  \begin{itemize}
    \item Le credenze dipendono dalle prove. Tutti gli enunciati indicheranno sempre le prove alla base degli assegnamenti di probabilità. 
    \item Due casi:
      \begin{itemize}
        \item Probabilità a priori: in assenza di prove. 
        \item Probabilità a posteriori: dopo avere osservazioni.
      \end{itemize}
  \end{itemize}
}

\paragraph{Prendere decisioni razionali:}

\begin{itemize}
  \item Attribuiamo a $A_{90}$ probabilità $95\%$ di successo. 
  \item $A_{120}$ e $A_{1440}$ avranno probabilità anche maggiori ma sono necessariamente migliori?
  \item Per prendere \fancyglitter{decisioni razionali} un agente deve avere preferenza sugli esiti delle sue azioni. 
  \item La \fancyglitter{teoria dell'utilità} attribuisce a ogni esito un grado di utilità per l'agente e permette all'agente di ragionare su esiti alternativi. 
  \item Teoria delle decisioni = Teoria delle Probabilità + Teoria dell'Utilità.
\end{itemize}

\clm{Convenzioni sulla notazione}{}{
  \begin{itemize}
    \item \fancyglitter{Variabile casuale} si riferisce a una parte del mondo il cui stato è inizialmente sconosciuto. 
    \item Le probabilità sono associate a proposizioni del tipo $X = Val$ dove $X$ è la variabile casuale discreta e $val$ è un valore del suo dominio. 
    \item Con lettere minuscole $a, b, c$ si indica variabili casuali generiche. 
    \item Con lettere maiuscole si indicano variabili casuali di un dominio specifico. 
  \end{itemize}
}


\paragraph{Assiomi delle probabilità:}

\begin{itemize}
  \item Per qualsiasi proposizione $a$ e $b$: 
    \begin{enumerate}
      \item $0 \leq P(a) \leq 1$
      \item $P(\text{true}) = 1$ \quad e \quad $P(\text{false}) = 0$
      \item $P(a \lor b) = P(a) + P(b) - P(a \land b)$
    \end{enumerate}
  \item Questi assiomi sono detti \fancyglitter{assiomi di Kolmogorov}.
  \item Motivazioni:
    \begin{itemize}
      \item L’uso degli assiomi nella rappresentazione di “gradi di belief” come probabilità garantisce razionalità e consistenza delle decisioni.
      \item I CF sono un esempio di gradi di belief che non soddisfano gli assiomi: trade-off tra poter ragionare con regole di buon senso e complessità computazionale.
    \end{itemize}
\end{itemize}

\dfn{Evento Atomico}{
  Specifica completa dello stato del mondo. È un assegnamento di valori a tutte le variabili casuali. 
}

\paragraph{Proprietà degli eventi atomici:}

\begin{itemize}
  \item Sono mutuamente esclusivi. 
  \item L'insieme di tutti gli eventi atomici descrive la verità o la falsità di qualsiasi proposizione (semplice o complessa). 
  \item Ogni proposizione è logicamente equivalente alla disgiunzione di tutti gli eventi atomici che ne implicano la verità. 
  \item In generale, dati $e(a)$ insieme degli eventi atomici dove $a$ è vera, $$P(a) = \displaystyle\sum_{e_i \in e(a)} P(e_i)$$ 
\end{itemize}

\subsection{Probabilità a Priori e a Posteriori}

\dfn{Probabilità a Priori}{
  È il grafo di credenza in una proposizione $a$ in \fancyglitter{assenza di ogni altra informazione}.
}

\cor{Distribuzione di Probabilità}{
  La distribuzione di probabilità a priori è un vettore di valori di probabilità: uno per ogni valore del dominio della variabile casuale considerata. 
}

\nt{I valori sono normalizzati in modo che la somma sia uguale a 1.}

\cor{Distribuzione di Probabilità Congiunta}{
  È una matrice che assegna un valore di probabilità a ogni possibile combinazione di valori delle variabili considerate. 
}

\nt{La distribuzione di probabilità congiunta è completa se costruita su tutte le variabili del dominio.}

\dfn{Probabilità Condizionate (a Posteriori)}{
  $P(a|b)$ è la probabilità di $a$ quando tutto ciò che sappiamo è $b$: 
  $$P(a|b) = \displaystyle\frac{P(a \land b)}{P(b)}$$
  quando $P(b) \not = 0$.
}

\cor{Regola del Prodotto}{
  $$P(a \land b) = P(a|b)*P(b) = P(b|a)*P(a)$$
}

\nt{Le probabilità condizionate non sono implicazioni logiche con incertezze. Inoltre le probabilità condizionate non sono monotone.}

\subsection{Inferenze con Distribuzioni di Congiunzione Complete}

\dfn{Inferenza Probabilistica}{
  Calcolo delle probabilità a posteriori poste come interrogazioni (query) partendo dalle prove osservate.
}

\cor{Regola del Condizionamento}{
  $$P(Y) = \displaystyle\sum_{z} P(Y|z)*P(z)$$
}

\nt{Nella maggior parte dei casi è interessante calcolare la probabilità condizionata di qualche variabile, avendo a disposizione altre variabili come prova. }

\cor{Inferenza Generale}{
  $$P(X|e) = \alpha P(X, e) = \alpha \displaystyle\sum_{y} P(X, e, y)$$

  In cui:
  \begin{itemize}
    \item E: variabili di evidenza. 
    \item Y: variabili nascoste. 
    \item X: variabili di query.
  \end{itemize}
}

\paragraph{Questa procedura ha due svantaggi:}

\begin{itemize}
  \item È computazionalmente costosa. 
  \item Costruire la distribuzione congiunta completa non è sempre possibile nei casi reali.
\end{itemize}

\section{Regola di Bayes}

\dfn{Indipendenza}{
  $a$ e $b$ sono indipendenti tra di loro se e solo se $P(a|b) = P(a)$ o $P(b|a) = P(b)$ o $P(a \land b) = P(a) * P(b)$.
}

\nt{Nei domini reali l'Indipendenza assoluta è rara.}

\dfn{Regola di Bayes}{
  $$P(b|a) = \displaystyle\frac{P(a|b) * P(b)}{P(a)}$$
}

\nt{Il teorema di Bayes può essere generalizzato.}

\dfn{Regola di Bayes e Condizionamento all'Evidenza}{
  $$P(Y|X, e) = \displaystyle\frac{P(X|Y, e) * P(Y|e)}{P(X|e)}$$
dove $e$ è un vettore di valori alle variabili di prova.
}

