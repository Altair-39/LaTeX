\chapter{Apprendimento e Reti Neurali}

\section{Apprendimento}

\subsection{Introduzione alla Classificazione}

\paragraph{Il problema:}

\begin{itemize}
	\item Dati:
	      \begin{itemize}
		      \item Esempi.
		      \item Categorie/classi.
	      \end{itemize}
	\item Costruire:
	      \begin{itemize}
		      \item Una rappresentazione astratta (modello) che permetta di
		            associare in modo corretto nuove istanze alla classe (o alle
		            classi) di appartenenza.
	      \end{itemize}
\end{itemize}

\dfn{Apprendimento Supervisionato}{
	Gli esempi dal quale astrarre le definizioni delle classi hanno associata la classe a cui appartengono.
}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{05/apprendimento.png}
	\caption{Schema generale.}
\end{figure}

\cor{Learning Set}{
	Per learning (o training) set si intende la collezione di dati usati per svolgere il
	compito di apprendimento. I dati sono divisi in istanze (o record o esempi). Ogni
	esempio è rappresentato da una tupla (x, y) dove x è a sua volta una tupla di valori
	di attributi descrittivi e y è la classe di appartenenza dell'istanza.
}

\paragraph{Uso dei modelli appresi:}

\begin{itemize}
	\item \fancyglitter{Predittivo:} viene usato per predire la classe
	      di appartenenza di istanze ignote
	      in fase di apprendimento.
	\item \fancyglitter{Descrittivo:} Viene usato come strumento esplicativo
	      che permette di evidenziare quali carat-
	      teristiche distinguono le diverse categorie.
\end{itemize}

\qs{}{Ma qual è la bontà dei modelli appresi?}

\dfn{Valutazione Sperimentale}{
	Il modello viene usato per classificare le istanze di un
	test set. La valutazione della bontà è fatta sulla base del comportamento di classificazione corretto/sbagliato su questi dati.
}

\paragraph{Proprietà:}

\begin{itemize}
	\item \fancyglitter{Accuratezza} = predizioni corrette / predizioni totali.
	\item \fancyglitter{Error Rate} = predizioni sbagliate / predizioni totali.
\end{itemize}

\cor{Matrice di Confusione}{
	Matrice quadrata $N x N$ (con $N$ numero di classi). Le righe indicano le classi reali di appartenenza, le colonne indicano le classi predette.
}

\nt{L'ideale è che tutte le predizioni stiano sulla diagonale principale.}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{05/confusion.png}
	\caption{Matrice di confusione.}
\end{figure}

\cor{Matrice dei Costi}{
	Matrice $N x N$ (con $N$ numero di classi). Associa un costo allo indovinare/sbagliare una predizione.
}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{05/cost.png}
	\caption{Matrice dei costi.}
\end{figure}

\subsection{Costruire un Modello}

\dfn{Rote Learning (Apprendimento Meccanico)}{
	Si tratta di memorizzare le varie istanze. Tramite confronti cerca un’istanza
	identica:
	\begin{itemize}
		\item Se la trova restituisce la classe corrispondente.
		\item Se non la trova prova a indovinare (cerca istanze simili utilizzando una misura di distanza).
	\end{itemize}
}

\paragraph{Strategie per decidere:}

\begin{itemize}
	\item Votazione a Maggioranza: la classe più votata vince.
	\item Votazione pesata: ogni voto ha un peso maggiore/minore a seconda
	      della “distanza” fra le istanze considerate.
\end{itemize}

\nt{
	In caso di votazione pesata, i pesi vengono
	calcolati, usati e poi dimenticati.
}

\paragraph{Algoritmi di apprendimento diversi producono modelli di tipo diverso:}

\begin{itemize}
	\item Alberi di decisione: albero.
	\item Sistemi a regole: if-then.
	\item Reti neurali: matrici di numeri.
	\item Apprendimento per rinforzo: distribuzioni di
	      probabilità e matrici di numeri.
\end{itemize}

\nt{Nell'apprendimento automatico non sono importanti i numeri, ma cosa essi rappresentato e come sono ottenuti.}

\dfn{Alberi di Decisione}{
	Sono strumenti di supporto alle decisioni che
	usano modelli strutturati ad albero, comunemente utilizzati per esempio per la definizione
	di strategie mirate al conseguimento di un goal.
}

\nt{Per esempio i sottomenu a tendina sono alberi di decisione.}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{05/dec.png}
	\caption{Struttura di un albero di decisione.}
\end{figure}

\clm{}{}{
	\begin{itemize}
		\item Ogni test è su un attributo.
		\item Le foglie sono classi.
		\item A ogni branch dell'albero si prende una decisione sulla base di un test e si scende al nodo successivo.
		\item Un dataset noto è il dataset degli iris.
	\end{itemize}
}

\paragraph{Tipi di attributi:}

\begin{itemize}
	\item Binari: booleani.
	\item Nominali: che hanno un nome.
	\item Ordinali: per cui vale un ordine.
	\item Continui.
\end{itemize}

\dfn{Algoritmo di Hunt}{
	L'albero viene costruito procedendo ricorsivamente e suddividendo il learning
	set in sottoinsiemi via via più “puri”.

	Dati:

	\begin{itemize}
		\item $D_t$ = sottoinsieme del learning set associato al nodo $t$.
		\item $y = \{y_1, y_2, \dots, y_c\}$ = insieme delle etichette che identificano le classi.
	\end{itemize}
}

\paragraph{Algoritmo di Hunt:}

\begin{enumerate}
	\item Se tutte le istanze in $D_t$ appartengono alla stessa classe $y_t$ allora il nodo
	      è una foglia etichettata dalla classe $y_t$ delle sue istanze.
	\item Si sceglie un attributo fra quelli che descrivono le istanze, si produce un
	      nodo figlio per ogni possibile valore dell'attributo.
\end{enumerate}

\clm{}{}{
	\begin{itemize}
		\item Se una certa combinazione di valori non è rappresentata da nessuna
		      istanza, questa sarà associata alla classe di default (se esiste).
		\item Se tutte le istanze associate a un nodo sono identiche come tuple ma
		      corrispondono a classi differenti (non-determinismo), il nodo non può
		      essere scisso.
		\item Quando si termina la costruzione dell'albero?
		\item Come si sceglie l'attributo di split?
	\end{itemize}
}

\paragraph{Tipi di split:}

\begin{itemize}
	\item Su attributi binari: Il nodo corrente avrà due figli a seconda del
	      valore rappresentato. Gli esempi associati
	      al nodo radice verranno suddivisi fra i due
	      figli a seconda del valore riportato in corrispondenza dell'attributo.
	\item Su attributi multivalore: l nodo avrà tanti figli quanti sono i possibili valori dell'attributo.
	\item Su attributi nominali: l'attributo assume valori su un insieme (finito) di etichette $\{L_1, L_2, \dots, L_n\}$. Gli split possono essere binari oppure multivalore.
	\item Su attributi nominali: si possono avere split binari o multivalore con un vincolo, il
	      raggruppamento dei valori deve rispettare l'ordinamento.
	\item Binari di attributi continui: in questo caso il test prevedono l'identificazione di un valore possibile v per
	      l'attributo A in questione.
	\item Multivalore di attributi continui: in questo caso il test prevedono l'identificazione di un insieme di valori $v_i$ per
	      l'attributo A in questione e la produzione di una serie di test $v_i \leq A < v_{i+1}$
\end{itemize}

\paragraph{Bontà degli split:}

\begin{itemize}
	\item \fancyglitter{Criterio generale:} alberi compatti sono preferiti ad alberi che consentono di
	      raggiungere lo stesso grado di accuratezza (e di error rate) usando un maggior
	      numero di test. Sono preferiti gli split che producono nodi figli la cui estensione
	      prevede minore confusione (il cui grado di purezza è maggiore). Misure alternative: entropia, gini, errore di classificazione.
	\item \fancyglitter{Rasoio di Occam:} a parità di assunzioni, la spiegazione più semplice è da
	      preferire.
\end{itemize}

\dfn{Entropia}{
	Serve per capire quanto sia confuso un insieme, più bassa è meglio è.
	\[
		\text{Entriopia}(t) = - \displaystyle\sum_{i=0}^{c-1} p(i|t) \text{log}_2 p(i|t)
	\]
	Dove $P(i|t)$ è la probabilità che l'elemento appartenenga all' i-esima classe.

}

\cor{Calcolo del Guadagno}{
	Formula per calcolare il guadagno di uno split.
	\[
		\Delta = I(\text{parent}) - \displaystyle\sum_{j=1}^{k} \displaystyle\frac{N(v_j)}{N} I(v_j)
	\]
}

\paragraph{Guadagno:}

\begin{itemize}
	\item $\Delta$ = guadagno.
	\item $I(\text{parent})$ = impurità del nodo genitore.
	\item $N$ = numero record del nodo genitore.
	\item $N(v_j)$ = numero dei record del nodo figlio j-mo.
	\item $I(v_j)$ = impurità del figlio j-mo.
\end{itemize}

\nt{Si vuole minimizzare l'impurità e massimizzare il guadagno.}

\cor{Information Gain}{
	Per information gain si intende una misura del guadagno ottenuta usando
	l'entropia come valore dell'impurità dei nodi.
	\[
		\Delta = \text{entropia(parent)} - \displaystyle\sum_{j=1}^{k} \displaystyle\frac{N(v_j)}{N} \text{entropia}(v_j)
	\]
}

\nt{
	Le misure del grado di confusione, come Gini ed entropia tendono a favorire
	attributi che hanno molti valori diversi rispetto ad attributi con pochi valori alternativi.
}








