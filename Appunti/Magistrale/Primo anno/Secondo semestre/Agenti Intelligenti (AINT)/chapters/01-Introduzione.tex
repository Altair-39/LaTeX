\chapter{Introduzione}

\section{Perché Agenti Intelligenti?}

\paragraph{La storia della computazione è stata definità da 5 trends:}


\begin{itemize}
  \item \fancyglitter{Ubiquità}. 
  \item \fancyglitter{Interconnessione}. 
  \item \fancyglitter{Intelligenza}. 
  \item \fancyglitter{Delega}. 
  \item \fancyglitter{Human-orientation}.
\end{itemize}

\paragraph{Ubiquità:}

\begin{itemize}
  \item La continua riduzione dei costi di elaborazione ha permesso di introdurre capacità di elaborazione in luoghi e dispositivi che una volta sarebbero stati antieconomici. 
  \item Ma mano che la capacità di elaborazione si diffonde, elementi sofisticati e intelligenti diventano onnipresenti.
\end{itemize}

\paragraph{Interconnessione:}

\begin{itemize}
  \item I sistemi informatici, attualmente, non esistono più da soli, ma sono collegati in rete in grandi sistemi distribuiti.
\item Per esempio internet. 
\item Alcuni ricercatori stanno proponendo modelli teorici che ritraggono l'informatica principalmente come un processo di interazione.
\end{itemize}

\paragraph{Intelligenza e Delega:}

\begin{itemize}
  \item La complessità dei compiti che siamo capaci di automatizzare e delegare ai computer è cresciuta costantemente. 
  \item Viene dato più controllo ai computer: 
    \begin{itemize}
      \item \textit{Fly-by wire aircraft}. 
      \item \textit{Fly-by-wire cars}.
    \end{itemize}
\end{itemize}

\paragraph{Human-orientation:}

\begin{itemize}
  \item CI si sposta da una vista orientata alla macchina e alla programmazione verso una visione a metafore e concetti più vicine alla comprensione umana. 
  \item I programmatori concettualizzano e realizzano software in termini di livello superiore, più orientato all'uomo, \fancyglitter{astrazioni}.
\end{itemize}

\nt{Delega e intelligenza implicano la necessità di costruire sistemi informatici in grado di agire efficacemente.}

\paragraph{Questo implica:}

\begin{itemize}
  \item La capacità di agire dei sistemi informatici \fancyglitter{in modo indipendente}\footnote{Un oggetto fa qualcosa perché la deve fare, un agente fa qualcosa perché la vuole fare. Hey non avevo idea di essere diventat un oggetto quando mi sono iscritt all'università.}. 
  \item La capacità dei sistemi informatici di agire in un modo che \fancyglitter{rappresentino nel migliore dei modi i nostri interessi} durante l'interazione con altri esseri umani o sistemi.
  \item Interconnessione e distribuzione portano a sistemi che possono \fancyglitter{cooperare} e \fancyglitter{raggiungere accordi}, \fancyglitter{agreements} o \fancyglitter{competere} con altri sistemi che hanno interessi diversi.
  \item Tutto ciò porta alla nascita di un nuovo campo dell'informatica: \fancyglitter{sistemi multiagente}.
\end{itemize}

\subsection{Agenti e Sistemi Multiagente}

\dfn{Agente}{
  Un agente è un sistema di compilazione, un sistema informatico, capace di agire in modo indipendente per conto di un utente o proprietario (capendo cosa deve essere fatto per soddisfare gli obiettivi di progettazione, piuttosto che essere costantemente informato).
}

\dfn{Sistema Multiagente}{
  Un sistema multiagente (MAS) consiste in una serie di agenti, che interagiscono l'uno con l'altro. Nel caso più generale, gli agenti agiscono per conto di utenti con differenti obiettivi e mtivazioni.
}

\nt{per interagire con successo, richiedono la capacità di \fancyglitter{cooperare}, \fancyglitter{coordinarsi} e \fancyglitter{negoziare} tra loro.}

\paragraph{Un sistema multiagente risponde a queste domande:}

\begin{itemize}
  \item Come può emergere la cooperazione in società composte da agenti \textit{self-interested}?
  \item Quali tipi di linguaggi possono essere utilizzati dagli agenti per comunicare?
  \item Come possono gli agenti \textit{self-interested} riconoscere conflitti? E come possono raggiungere accordi?
  \item Come possono gli agenti autonomi coordinare le proprie attività in modo da raggiungere cooperativamente gli obiettivi?
\end{itemize}

\paragraph{Ma soprattutto:}

\begin{itemize}
  \item Come possiamo creare agenti capaci di agire in modo indipendente, autonomo, in modo che possano svolgere con successo i compiti che gli deleghiamo?
  \item Come possiamo creare agenti capaci di interagire con altri agenti con il fine di portare a termine con successo i compiti delegati, soprattutto quando non si può presumere che gli altri agenti condividano gli stessi interessi e obiettivi?
\end{itemize}

\clm{}{}{
  \begin{itemize}
    \item Il primo caso è un problema di progettazione/design di un agente. 
    \item Il secondo caso è un problema di progettazione/design di società di agenti.
  \end{itemize}
}

\subsection{Approccio Interdisciplinare}

\paragraph{Il campo dei sistemi multiagente è influenzato e ispirato da molti altri campi:}

\begin{itemize}
  \item Economia. 
  \item Filosofia. 
  \item Teoria dei giochi. 
  \item Logica. 
  \item Ecologia. 
  \item Scienze sociali.
\end{itemize}

\nt{Questo è sia un punto di forza (perché ci sono molte idee diverse) sia un punto di debolezza (perché ci sono molte idee diverse lol).}

\qs{}{Non è solo AI?}

\begin{itemize}
  \item Non abbiamo bisogno di risolvere tutti i problemi di intelligenza artificiale per costruire agenti utili. 
  \item L'AI classica ignorava gli aspetti sociali dell'agire.
\end{itemize}

\qs{}{Non è solo economia/teoria dei giochi?}

\begin{itemize}
  \item Nella misura in cui la teoria dei giochi fornisce descrizione di concetti, non sempre ci dice come calcolare soluzioni. 
  \item Alcune assunzioni in economia/teoria dei giochi potrebbero non essere valide o utili nella costruzione di agenti artificiali.
\end{itemize}

\qs{}{Non sono solo scienze sociali?}

\begin{itemize}
  \item Possiamo trarre spunti dallo studio di società umane, ma non ci sono particolari motivi per credere che le società artificiali siano costruite allo stesso modo\footnote{Effettivamente sarebbe raccapricciante se gli agenti cominciassero a uccidersi a vicenda per questioni triviali.}. 
  \item Si trae ispirazione, ma non si assume a prescindere.
\end{itemize}
\pagebreak

\section{Cosa si Intende per Agenti Intelligenti?}

Ricordiamo che un agente è un sistema di computazione capace di agire \fancyglitter{autonomamente} in un qualche \fancyglitter{ambiente} con il fine di raggiungere gli \fancyglitter{obiettivi} per cui è progettato.

\nt{La caratteristica principale degli agenti e la loro autonomia.}

  \begin{figure}[h]
    \centering
    \includegraphics[scale=0.7]{01/ae.png}
    \caption{Agente che interagisce con l'ambiente.}
    \label{fig:ae}

  \end{figure}

\nt{In figura \ref{fig:ae} il fatto che l'agente e l'ambiente sono disegnati con due rettangoli identici non è casuale: sono due elementi alla pari.}

\ex{Agenti}{
  \begin{center}
    \includegraphics[scale=0.55]{01/ta.png}
  \end{center}
}

\paragraph{Autonomia e controllabilità:}

\begin{itemize}
  \item Al di fuori della comunità AI, gli agenti autonomi intelligenti sono percepiti come entità consapevoli di sé, incontrollabili, la cui autonomia emerge come proprietà "extra-programma". 
  \item Un agente può prendere iniziative che non sono incluse fin dall'inizio nel suo programma.
\end{itemize}
\pagebreak
\subsection{Test di Turing}

\paragraph{Il test di Turing:}

\begin{itemize}
  \item Una persona o un computer sono nascosti a un investigatore (fig. \ref{fig:Turing}).
  \begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{01/turing1.png}
    \caption{Rappresentazione del test di Turing.}
    \label{fig:Turing}
  \end{figure}
   \item Interazione:
     \begin{itemize}
      \item L'investigatore pone domande scritte. 
      \item L'entità nascosta fornisce risposte scritte. 
      \item L'investigatore deve capire se dall'altra parte c'è un computer o una persona. Se all'altra parte c'è un computer e l'investigatore non riesce a distinguerlo allora il computer si può dire \fancyglitter{intelligente}.
     \end{itemize}
   \item Basta produrre gli output attesi per dire che vi è comprensione? (fig. \ref{fig:Turing2})
  \begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{01/turing2.png}
    \caption{Scambio di messaggi.}
    \label{fig:Turing2}
  \end{figure}
\end{itemize}

\paragraph{Esperimento di J. Searle (la stanza cinese):}

\begin{itemize}
  \item Un computer, programmato per rispondere con certi ideogrammi cinesi ad altri ideogrammi cinesi ricevuti in input (fig. \ref{fig:Searle}. L'interlocutore umano che parla in cinese non vede il computer che è chiuso in una stanza. Cosa penserà di chi è nella stanza?
  \begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{01/searle1.png}
    \caption{Rappresentazione dell'esperimento di Searle.}
    \label{fig:Searle}
  \end{figure}
\item Il computer parla cinese? Lo capisce? 
\item Una persona chiusa in una stanza ha istruzioni per rispondere con certi ideogrammi cinesi in risposta ad altri ideogrammi cinesi (fig. \ref{fig:Searle2}). 
    \begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{01/searle2.png}
    \caption{Esperimento con una persona.}
    \label{fig:Searle2}
  \end{figure}
\item Scrivere un programma per un computer non è di per sé una condizione sufficiente per implicare l'intenzionalità.
\end{itemize}

\nt{Searle ha scelto il cinese perché voleva considerare una lingua difficile da capire. Per me è skill issue.}

\paragraph{AI:}

\begin{itemize}
  \item \fancyglitter{AI forte}: è possibile riprodurre l'intelligenza umana? Compresa la consapevolezza di sé, l'essere senziente, etc. 
  \item \fancyglitter{AI debole}: esistono modi automatici per risolvere problemi che a un essere umano richiedono intelligenza? Task-oriented, studio del pensiero e del comportamento umano.
\end{itemize}

\subsection{Agenti Intelligenti}

\paragraph{Agenti triviali (non interessanti):}

\begin{itemize}
  \item Termostato. 
  \item UNIX deamon\footnote{Come si permette di dire che il daemon UNIX non è interessante. Probabilmente non ha mai speso il pomeriggio a riaggiustarlo dopo aver rotto un arch install >:(}
\end{itemize}

\paragraph{Un agente intellingente deve eseguire azioni in modo \fancyglitter{flessibile}:}

\begin{itemize}
  \item \fancyglitter{Reattivo}. 
  \item \fancyglitter{Proattivo}. 
  \item \fancyglitter{Sociale}.
\end{itemize}

\clm{}{}{
  \begin{itemize}
    \item Se l'ambiente di un software è statico/fisso non è necessario preocuparsi di esso (e. g. un compilatore, un package manager). 
    \item Nel mondo reale le cose cambiano, le informazioni sono incomplete. 
    \item È necessario considerare la possibilità che l'esecuzione di azioni (istruzioni) non abbia successo, è necessario chiedersi se valga la pena eseguire una certa azione.
  \end{itemize}
}

\dfn{Agente Reattivo}{
  Un agente reattivo è un sistema che mantiene una costante interazione con l'ambiente e risponde ai cambiamenti he occorrono in esso (in tempo perché la risposta sia utile).
}

    \begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{01/agentereattivo.png}
    \caption{Un agente reattivo.}
  \end{figure}

  \nt{Può essere visto come un if then.}

\clm{}{}{
  \begin{itemize}
    \item Reagire a un ambiente è facile, però in generale, si vuole che gli agenti "facciano cose per noi". 
    \item \fancyglitter{Goal directed behaviour}: comportamento guidato dagli obiettivi.
    \item \fancyglitter{Proattività}: generare e tentare di raggiungere gli obiettivi, non solo guidati dagli eventi, ossia \fancyglitter{prendere l'iniziativa}. 
    \item Riconoscere le opportunità.
  \end{itemize}
}

\dfn{Agente Proattivo}{
  Lo stato dell'agente contiene due tipi di conoscenza:
  \begin{itemize}
    \item L'agente necessita di informazioni su come l'ambiente evolve. 
    \item L'agente necessità di informazioni su come le proprie azioni impattano sull'ambiente.
  \end{itemize}
  L'agente necessita di informazioni sull'\newfancyglitter{obiettivo} (goal) in modo che l'agente possa agire per raggiungerlo. Nel farlo l'agente deve essere in grado di lavorare su \newfancyglitter{piani}.
}

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.7]{01/proattivo.png}
  \caption{Agente proattivo.}
\end{figure}

\paragraph{Reattivo vs. Proattivo:}

\begin{itemize}
  \item Si desidera che gli agenti siano reattivi e che rispondano ai cambiamenti per tempo. 
  \item Si desidera che gli agenti lavorino in modo sistematico verso obiettivi di lungo termini. 
  \item Queste due considerazioni possono essere in conflitto. 
  \item Progettare un agente che bilanci reattività e proattività è ancora un problema aperto.
\end{itemize}







